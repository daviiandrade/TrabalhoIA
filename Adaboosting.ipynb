{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daviiandrade/TrabalhoIA/blob/main/adaboosting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "toc": true,
        "id": "70lXs7DjtU4W"
      },
      "source": [
        "##Adaboosting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-20T21:49:20.851769Z",
          "start_time": "2020-04-20T21:49:20.849726Z"
        },
        "id": "mOlzOD9ktU4a"
      },
      "outputs": [],
      "source": [
        "# https://stats.stackexchange.com/questions/299688/logistic-regression-adaboost\n",
        "# https://towardsdatascience.com/boosting-algorithm-adaboost-b6737a9ee60c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-20T21:49:22.480683Z",
          "start_time": "2020-04-20T21:49:20.853714Z"
        },
        "id": "F1vs5dbotU4c"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_classification\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.base import clone\n",
        "from sklearn.base import BaseEstimator\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.decomposition import PCA\n",
        "# from logistic import Logistic_Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-20T21:49:22.494253Z",
          "start_time": "2020-04-20T21:49:22.480683Z"
        },
        "id": "x_gd9JRGtU4d"
      },
      "outputs": [],
      "source": [
        "def accuracy(y_true, y_pred):\n",
        "    accuracy = np.sum(y_true == y_pred) / len(y_true)\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-20T21:49:22.626326Z",
          "start_time": "2020-04-20T21:49:22.498240Z"
        },
        "hide_input": false,
        "id": "dhANqiOOtU4e"
      },
      "outputs": [],
      "source": [
        "# X, y = make_classification(n_samples=500, n_features=5, n_informative=3, n_classes=2, flip_y=0.4, random_state=42)\n",
        "# data = np.c_[X, y.ravel()]\n",
        "# data = pd.DataFrame(data, columns=[\"f1\", \"f2\", \"f3\", \"f4\", \"f5\", \"output\"])\n",
        "# data.head()\n",
        "\n",
        "# X = data[data.columns[:-1]].values\n",
        "# y = data[data.columns[-1]].values\n",
        "\n",
        "# x_train, x_val, y_train, y_val = train_test_split(X, y, test_size=0.2, shuffle=True, stratify=y, random_state=47)\n",
        "# len(x_train), len(x_val), len(y_train), len(y_val)\n",
        "\n",
        "# np.save(\"x_train\", x_train)\n",
        "# np.save(\"y_train\", y_train)\n",
        "# np.save(\"x_val\", x_val)\n",
        "# np.save(\"y_val\", y_val)\n",
        "\n",
        "# x_train = np.load(\"x_train.npy\")\n",
        "# y_train = np.load(\"y_train.npy\")\n",
        "# x_val = np.load(\"x_val.npy\")\n",
        "# y_val = np.load(\"y_val.npy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXiO-PKktU4f"
      },
      "source": [
        "# MODELO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-20T21:49:22.756649Z",
          "start_time": "2020-04-20T21:49:22.628321Z"
        },
        "id": "7vMAusvKtU4f"
      },
      "outputs": [],
      "source": [
        "from sklearn.base import BaseEstimator\n",
        "\n",
        "\n",
        "class Logistic_Regression(BaseEstimator):\n",
        "    \n",
        "    def __init__(self, learning_rate=0.01, epochs=1000):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.epochs = epochs\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "        self.cost_per_iteration = []\n",
        "        \n",
        "    \n",
        "    def _sigmoid(self, x):\n",
        "        EPS = 1e-7\n",
        "        return 1 / (1 + np.exp(-x + EPS))\n",
        "    \n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        m, n = X.shape\n",
        "        self.weights = np.zeros(n)\n",
        "        self.bias = 0\n",
        "        \n",
        "\n",
        "        for _ in range(self.epochs):\n",
        "\n",
        "            Z = np.dot(X, self.weights) + self.bias\n",
        "            A = self._sigmoid(Z)\n",
        "            \n",
        "            dw = (1 / m) * np.dot(X.T, A - y)\n",
        "            db = (1 / m) * np.sum(A - y)\n",
        "            \n",
        "            self.weights -= self.learning_rate * dw\n",
        "            self.bias -= self.learning_rate * db\n",
        "            \n",
        "    def predict(self, X):\n",
        "        Z = np.dot(X, self.weights) + self.bias\n",
        "        A = self._sigmoid(Z)\n",
        "    \n",
        "        if not isinstance(A, float):\n",
        "            y_predicted_cls = [1 if i >= 0.5 else 0 for i in A]\n",
        "        else:\n",
        "            y_predicted_cls = 1 if A >= 0.5 else 0\n",
        "        return y_predicted_cls\n",
        "    \n",
        "    \n",
        "    def __str__(self):\n",
        "        return f\"Logistic_Regression(learning_rate={self.learning_rate}, epochs={self.epochs})\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-20T21:49:22.888720Z",
          "start_time": "2020-04-20T21:49:22.759680Z"
        },
        "id": "rNixGbN7tU4g"
      },
      "outputs": [],
      "source": [
        "class AdaBoost(object):\n",
        "    \n",
        "    def __init__(self, base_estimator, n_estimators, learning_rate):\n",
        "        self.base_estimator = base_estimator\n",
        "        self.n_estimators = n_estimators\n",
        "        self.learning_rate = learning_rate\n",
        "        self.predictor_weightages = []\n",
        "        \n",
        "        \n",
        "    def fit(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "        \n",
        "        for i in range(self.n_estimators):\n",
        "\n",
        "            instance_weights = self._initial_instance_weights(n_samples)\n",
        "            \n",
        "            clone_clf = clone(self.base_estimator)\n",
        "            clone_clf.fit(X, y)\n",
        "            predicted = clone_clf.predict(X)\n",
        "            \n",
        "            mis_classified_instances, acc = self._getAccuracy(y, predicted)\n",
        "            \n",
        "            total_err = self._total_error(mis_classified_instances, instance_weights)\n",
        "            \n",
        "            predictor_weightage = self._get_predictor_weightage(total_err)\n",
        "            self.predictor_weightages.append((i, clone_clf, predictor_weightage))\n",
        "            \n",
        "            instance_weights = self._update_instance_weights(mis_classified_instances, \n",
        "                                                             instance_weights, predictor_weightage)\n",
        "\n",
        "            X, y = self._new_sample_set(X, y, instance_weights)\n",
        "\n",
        "    \n",
        "\n",
        "    def _initial_instance_weights(self, shape):\n",
        "        instance_weights = np.full(shape=shape, fill_value=1/shape)\n",
        "        return instance_weights\n",
        "    \n",
        "    \n",
        "    def _getAccuracy(self, true, predicted):\n",
        "        assert len(true) == len(predicted)\n",
        "        error_instance = np.equal(true, predicted).astype(int)\n",
        "        miss_classified = []\n",
        "\n",
        "        for i, j in enumerate(error_instance):\n",
        "            if j == 0:\n",
        "                miss_classified.append(i)\n",
        "                \n",
        "        accuracy = np.sum(true == predicted)\n",
        "        return miss_classified, (accuracy/len(true)) * 100.0\n",
        "    \n",
        "    \n",
        "    def _total_error(self, mis_classified, instance_weights):\n",
        "        error = 0\n",
        "        for i in mis_classified:\n",
        "            error += instance_weights[i]\n",
        "\n",
        "        return error\n",
        "    \n",
        "    def _get_predictor_weightage(self, error):\n",
        "        EPS = 1e-5\n",
        "        weightage = 0.5 * np.log((1.0 - error + EPS) / (error + EPS))\n",
        "        return weightage\n",
        "\n",
        "    \n",
        "    def _update_instance_weights(self, mis_classified_instances, instance_weights, predictor_weightage):\n",
        "        weights = instance_weights[:]\n",
        "        EPS = 1e-10\n",
        "        for idx in range(len(instance_weights)):\n",
        "            if idx in mis_classified_instances:\n",
        "                weights[idx] = weights[idx] * np.exp(predictor_weightage + EPS)\n",
        "            else:\n",
        "                weights[idx] = weights[idx] * np.exp(-predictor_weightage + EPS)\n",
        "\n",
        "\n",
        "        # Normalizing weights\n",
        "        summed_weights = np.sum(weights)\n",
        "        weights /= summed_weights\n",
        "        return np.array(weights)\n",
        "    \n",
        "    def _new_sample_set(self, X, y, instance_weights):\n",
        "        intervals = []\n",
        "        intervals.append(instance_weights[0])\n",
        "\n",
        "        for i, j in enumerate(instance_weights[1:], 1):\n",
        "            intervals.append(j + intervals[i-1])\n",
        "\n",
        "        idxs = []\n",
        "\n",
        "        for i in range(X.shape[0]):\n",
        "            samp = np.random.sample()\n",
        "            try:\n",
        "                idx = np.searchsorted(intervals, samp, side='right')\n",
        "                _ = X[idx] # check if exists\n",
        "            except:\n",
        "                idx = idx - 1\n",
        "\n",
        "            finally:\n",
        "                idxs.append(idx)\n",
        "\n",
        "        X = X[idxs]\n",
        "        y = y[idxs]\n",
        "        return X, y\n",
        "    \n",
        "    def predict(self, X):\n",
        "        clf_predictions = np.array([clf.predict(X) for idx, clf, weightage in self.predictor_weightages])\n",
        "        predictions = []\n",
        "        \n",
        "        for sample_predictions in clf_predictions.T:\n",
        "            class_0 = 0\n",
        "            class_1 = 0\n",
        "            \n",
        "            for predictor, predictor_op in enumerate(sample_predictions):\n",
        "                if predictor_op == 0:\n",
        "                    class_0 += self.predictor_weightages[predictor][2]\n",
        "                else:\n",
        "                    class_1 += self.predictor_weightages[predictor][2]\n",
        "            \n",
        "            if class_0 > class_1:\n",
        "                predictions.append(0)\n",
        "            else:\n",
        "                predictions.append(1)\n",
        "        \n",
        "        return np.array(predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fFaBSK_tU4i"
      },
      "source": [
        "# Treinando e testando em Diabetes dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-20T21:49:23.035131Z",
          "start_time": "2020-04-20T21:49:22.893705Z"
        },
        "id": "3RDsOzigtU4j",
        "outputId": "183dd483-bd7e-44d4-fc5d-8faf5cfc5f6e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
              "0            6      148             72             35        0  33.6   \n",
              "1            1       85             66             29        0  26.6   \n",
              "2            8      183             64              0        0  23.3   \n",
              "3            1       89             66             23       94  28.1   \n",
              "4            0      137             40             35      168  43.1   \n",
              "\n",
              "   DiabetesPedigreeFunction  Age  Outcome  \n",
              "0                     0.627   50        1  \n",
              "1                     0.351   31        0  \n",
              "2                     0.672   32        1  \n",
              "3                     0.167   21        0  \n",
              "4                     2.288   33        1  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "diabetes_data = pd.read_csv(r'../datasets/diabetes_data.csv')\n",
        "diabetes_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-20T21:49:23.164183Z",
          "start_time": "2020-04-20T21:49:23.037126Z"
        },
        "id": "vwTI88IStU4j"
      },
      "outputs": [],
      "source": [
        "X = diabetes_data[diabetes_data.columns[:-1]].values\n",
        "y = diabetes_data[diabetes_data.columns[-1]].values\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-20T21:49:23.280115Z",
          "start_time": "2020-04-20T21:49:23.165971Z"
        },
        "id": "O_G_D_ebtU4k"
      },
      "outputs": [],
      "source": [
        "ada_clf = AdaBoost(base_estimator=Logistic_Regression(learning_rate=0.001, epochs=500),\n",
        "                  n_estimators=10, learning_rate=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-20T21:49:24.024679Z",
          "start_time": "2020-04-20T21:49:23.283107Z"
        },
        "id": "-_2Ra_0JtU4k"
      },
      "outputs": [],
      "source": [
        "ada_clf.fit(X_train, y_train)\n",
        "y_pred = ada_clf.predict(X_train)\n",
        "print(f\"Training Accuracy: {round(accuracy(y_train, y_pred), 2)}\")\n",
        "\n",
        "y_pred = ada_clf.predict(X_test)\n",
        "print(f\"Validation Accuracy: {round(accuracy(y_test, y_pred), 2)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-17T16:09:02.009602Z",
          "start_time": "2020-04-17T16:09:00.761505Z"
        },
        "id": "Rk6kkCVCtU4l"
      },
      "source": [
        "# MÃ©tricas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-20T21:49:24.030660Z",
          "start_time": "2020-04-20T21:49:24.026672Z"
        },
        "id": "ZoF0ozjNtU4l"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-20T21:49:24.139410Z",
          "start_time": "2020-04-20T21:49:24.031658Z"
        },
        "id": "pn6-m3y3tU4l"
      },
      "outputs": [],
      "source": [
        "print(f\"Model Precision: {precision_score(y_test, y_pred)}\")\n",
        "print(f\"Model Recall: {recall_score(y_test, y_pred)}\")\n",
        "print(f\"Model F1-score: {f1_score(y_test, y_pred)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-20T21:49:24.268518Z",
          "start_time": "2020-04-20T21:49:24.140367Z"
        },
        "id": "cdBEygM0tU4m"
      },
      "outputs": [],
      "source": [
        "# roc curve \n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "fpr, tpr, thresholdsh = roc_curve(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-20T21:49:24.550950Z",
          "start_time": "2020-04-20T21:49:24.275501Z"
        },
        "id": "5luwQopetU4m"
      },
      "outputs": [],
      "source": [
        "def plot_roc_curve(fpr, tpr, label=None):\n",
        "    plt.plot(fpr, tpr, linewidth=2, label=label)\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    plt.axis([0, 1, 0, 1])\n",
        "    plt.xlabel('False Positive Rate (Fall-Out)', fontsize=16)\n",
        "    plt.ylabel('True Positive Rate (Recall)', fontsize=16)\n",
        "    plt.grid(True)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plot_roc_curve(fpr, tpr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-20T21:49:24.557936Z",
          "start_time": "2020-04-20T21:49:24.552948Z"
        },
        "id": "oMxVw7oLtU4m"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "roc_auc_score(y_test, y_pred)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": true,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "position": {
        "height": "463.534px",
        "left": "1077.82px",
        "right": "20px",
        "top": "138px",
        "width": "305.523px"
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "adaboosting.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
